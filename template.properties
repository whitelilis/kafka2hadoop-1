# name of test topic
kafka.etl.topic=${topic}

# hdfs location of jars
hdfs.default.classpath.dir=/tmp/kafka/lib

# number of test events to be generated
event.count=0

# hadoop id and group
hadoop.job.ugi=kafka,supergroup

# kafka server uri
kafka.server.uri=tcp://${broker}

# hdfs location of input directory
input=${hdfs_input}

# hdfs location of output directory
output=${hdfs_dir}/${bucket_name}

# limit the number of events to be fetched;
# value -1 means no limitation,
# however that is ill-adviced for restart scenarios
# in combination with large kafka retention windows
kafka.request.limit=200000000

# kafka parameters
client.buffer.size=1048576
client.so.timeout=60000
kafka.etl.files.per.request=500

# max kafka log files will be fetched from kafka and stored in a single file in hdfs
kafka.etl.kafka.maxKafkaLogsPerMapper=6

# maximum number of map tasks created per request
kafka.etl.kafka.maxMappersPerRequest=150
